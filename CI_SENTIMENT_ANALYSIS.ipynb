{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Text-Preprocessing file"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#text preprocess file\nimport unicodedata\nimport contractions  \nimport inflect       \nimport re\nfrom bs4 import BeautifulSoup\nfrom nltk import sent_tokenize\nfrom nltk.stem import LancasterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\n\ndef replace_contractions(text):\n    \"\"\"Replace contractions in string of text\"\"\"\n    return contractions.fix(text)\n\ndef remove_non_ascii(words):\n    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n        new_words.append(new_word)\n    return new_words\n\ndef to_lowercase(words):\n    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = word.lower()\n        new_words.append(new_word)\n    return new_words\n\ndef remove_punctuation(words):\n    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        new_word = re.sub(r'[^\\w\\s]', '', word)\n        if new_word != '':\n            new_words.append(new_word)\n    return new_words\n\ndef replace_numbers(words):\n    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n    p = inflect.engine()\n    new_words = []\n    for word in words:\n        if word.isdigit():\n            new_word = p.number_to_words(word)\n            new_words.append(new_word)\n        else:\n            new_words.append(word)\n    return new_words\n\ndef remove_stopwords(words):\n    \"\"\"Remove stop words from list of tokenized words\"\"\"\n    new_words = []\n    for word in words:\n        if word not in stopwords.words('english'):\n            new_words.append(word)\n    return new_words\n\ndef stem_words(words):\n    \"\"\"Stem words in list of tokenized words\"\"\"\n    stemmer = PorterStemmer()\n    stems = []\n    for word in words:\n        stem = stemmer.stem(word)\n        stems.append(stem)\n    return stems\n\ndef lemmatize_verbs(words):\n    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n    lemmatizer = WordNetLemmatizer()\n    lemmas = []\n    for word in words:\n        lemma = lemmatizer.lemmatize(word, pos='v')\n        lemmas.append(lemma)\n    return lemmas\n",
      "execution_count": 248,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Replacing the title in excel sheet"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\nxls = pd.ExcelFile('/Users/Sarath/Desktop/term-2/CI/ci_data_with_language/Label sheets/Final_one.xlsx')\ndf1 = pd.read_excel(xls, 'neg')",
      "execution_count": 565,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#removing the altmeric word in article name\ndef remove_alt(article_name):\n    k = article_name.split()\n    a = k[2:]\n    article_name = ' '.join(a)\n    return article_name\n    ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df1['article_name'] = df1['article_name'].apply(remove_alt)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from openpyxl import load_workbook\nfilepath=r'/Users/Sarath/Desktop/term-2/CI/ci_data_with_language/working_python/new_title_replaced_8.xlsx'\nbook=load_workbook(filepath)\nwriter = pd.ExcelWriter(filepath, engine='openpyxl',options={'strings_to_urls': False})\nwriter.book=book\ndf.to_excel(writer,sheet_name='tweet')\nwriter.save()\nwriter.close()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings(\"ignore\")\nimport re\ndef clean_tweet(tweet): #remove user name, special characters and urls\n    # removing urls\n    tweet = re.sub(r'https?://\\S+',' ',tweet)\n    # removing user names\n    user_names = re.findall(r\"(@[A-Za-z0-9]+)\", tweet)\n    #iterating to remove multiple user names\n    for i in user_names:\n        tweet = re.sub(i,' ', tweet)\n    # replacing the special characters and numbers\n    tweet = re.sub(r'([^A-Za-z\\s])',' ',tweet)\n    #replacing multiple spaces in to a single space\n    tweet = re.sub(' +',' ', tweet)\n    return tweet",
      "execution_count": 249,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# fuzzy function"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import re\nfrom fuzzywuzzy import fuzz\n",
      "execution_count": 250,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from fuzzywuzzy import fuzz\n#replacing the tile in tweets\ndef fuzzy_place_3(str_a, str_b, orig_str):\n    text = orig_str\n    str_a = str_a\n    l = len(str_a.split()) # Length to read orig_str chunk by chunk\n    \n    for i in range(len(text.split())-l+1):#trying to find the whole title in a tweet\n        new_splitted = text.split()\n        test = \" \".join(new_splitted[i:i+l])\n        if fuzz.ratio(str_a, test) > 85: #Using fuzzwuzzy library to test ratio\n            before = \" \".join(new_splitted[:i])\n            after = \" \".join(new_splitted[l+i:])\n            if before!= '':\n                text = before+\" \"+str_b+\" \"+after#Output will be sandwich of these three strings\n            else: \n                text = str_b+' '+after\n\n    for i in range(len(text.split())-4):#finding the 5 continuous title words in tweet\n        n_split = text.split()\n        test2 = ' '.join(n_split[i:i+5])\n        for j in range(l-5):\n            title_split = str_a.split()# to cover the title in the range of 5-8\n            title_tes = ' '.join(title_split[j:j+5])\n            #print('title_tes', title_tes)\n            if fuzz.ratio(title_tes, test2)> 85:\n                before = \" \".join(n_split[:i])\n                after = \" \".join(n_split[5+i:])\n                if before!= '':\n                    text = before+\" \"+str_b+\" \"+after#Output will be sandwich of these three strings\n                else: \n                    text = str_b+' '+after\n                    \n                    \n    return text\n        ",
      "execution_count": 251,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# additional features lexicons"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#negation count function\nimport nltk\nimport nltk.sentiment.sentiment_analyzer \ndef negation(tweet):\n    a = tweet.split()\n    b = nltk.sentiment.util.mark_negation(a)\n    tweet = ' '.join(b)\n    count = len(re.findall('\\w+_NEG', tweet))\n    return count",
      "execution_count": 252,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#reading  mpqa lexicon and creating a csv file to use it\n\nimport re\nf = open('new_lexicon.csv', 'w')\nwith open('subjclueslen1-HLTEMNLP05.tff', 'rb') as file:\n    for line in file.readlines():\n        line = str(line)\n       \n        m = re.search('.*word1=(\\S+).*pos1=(\\S+).*priorpolarity=(\\w+)', line)\n        if m.group(3) == 'positive':\n            score = 1\n        elif m.group(3) == 'negative':\n            score = -1\n        else:\n            score = 0\n        f.write(\"%s,%s,%s\\n\" % (m.group(1), str(score),m.group(2)))\n\nf.close()",
      "execution_count": 253,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating the python dictionary to hold the lexicons\nimport collections\nimport csv\nlexicon = collections.defaultdict(list)\n\nwith open('new_lexicon.csv', 'r') as csvFile:\n    reader = csv.reader(csvFile)\n    for row in reader:\n        lexicon[row[0]].append(int(row[1]))\n        lexicon[row[0]].append(row[2])\ncsvFile.close()   \n",
      "execution_count": 254,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#number of negative words in a tweet\ndef neg_word_count(tweet):\n    count = 0\n    for i in tweet.split():\n        #print(i)\n        if i in lexicon:\n            #print(i)\n            try: \n                score = lexicon[i][0]\n                #print('score',score)\n                if score == -1:\n                    count+=1            \n            except: pass\n    return count\n\n\n#no of positive words in a tweet\ndef pos_word_count(tweet):\n    count = 0\n    for i in tweet.split():\n        #print(i)\n        if i in lexicon:\n            #print(i)\n            try: \n                score = lexicon[i][0]\n                #print('score',score)\n                if score == 1:\n                    count+=1            \n            except: pass\n    return count\n\n#overall score of the tweet\ndef overall_score(tweet):\n    score = 0\n    for i in tweet.split():\n        if i in lexicon:\n            try:\n                a = lexicon[i][0]\n                score += a\n            except: \n                pass\n    return score\n\n#last token polarity\ndef las_pol(tweet):\n    tweet = tweet.split()\n    l_word = tweet[-1]\n    score = 0\n    if l_word in lexicon:\n        a = lexicon[l_word][0]\n        #print(a)\n        score = a\n        #print(score)\n    return score\n\n#number of adjectives, adverbs and verbs in a tweet\ndef pos_POStag_count(tweet):\n    count = 0\n    l = ['adj','adverb','verb']\n    for i in tweet.split():\n        if i in lexicon:\n            #print(i)\n            try:\n                pos_tag = lexicon[i][1]\n                if pos_tag in l:\n                    #print(lexicon[i])\n                    if lexicon[i][0] == 1:\n                        count+=1\n\n            except: \n                pass\n    return count  \n\n#number of adjectives, adverbs and verbs in a tweet\ndef neg_POStag_count(tweet):\n    count = 0\n    l = ['adj','adverb','verb']\n    for i in tweet.split():\n        if i in lexicon:\n            #print(i)\n            try:\n                pos_tag = lexicon[i][1]\n                if pos_tag in l:\n                    #print(lexicon[i])\n                    if lexicon[i][0] == -1:\n                        count+=1\n\n            except: \n                pass\n    return count  ",
      "execution_count": 255,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Additional Features emoji based"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# creating the function to calculate the emoticons count\nemoticon_file=\"emoticons.txt\"\nemoticons = {}\nfrom pathlib import Path\ncontent = Path(emoticon_file).read_text()\npositive = True\nfor line in content.split(\"\\n\"):\n    if \"positive\" in line.lower():\n        positive = True\n        continue\n    elif \"negative\" in line.lower():\n        positive = False\n        continue\n    emoticons[line] = positive\n\ndef pos_emo_count(tweet):\n    emo_count = []\n    for i in tweet.split():\n        if i in emoticons:\n            emo_count.append(emoticons[i])\n    new_lis = Counter(emo_count)\n    #print(new_lis)\n    pos_emo_count = new_lis[True]\n    #print(pos_emo_count)\n    #neg_emo_count = new_lis[False]\n    #print(neg_emo_count)\n    return pos_emo_count\n\ndef neg_emo_count(tweet):\n    emo_count = []\n    for i in tweet.split():\n        if i in emoticons:\n            emo_count.append(emoticons[i])\n    new_lis = Counter(emo_count)\n    #print(new_lis)\n    #pos_emo_count = new_lis[True]\n    #print(pos_emo_count)\n    neg_emo_count = new_lis[False]\n    #print(neg_emo_count)\n    return neg_emo_count\n\n#count occurences of a ! and ?\ndef count_occurences(character, word_array):\n            counter = 0\n            for j, word in enumerate(word_array):\n                for char in word:\n                    if char == character:\n                        counter += 1\n\n            return counter\n        \n#punctuation count\nimport string\ndef punc_count(text):\n    for i in text.split():\n        count = lambda l1,l2: sum([1 for x in l1 if x in l2])\n        punct = count(text,set(string.punctuation))\n    return punct\n    \n# count number of user name mentions\ndef user_mention_count(tweet):\n    user_names = re.findall(r\"(@[A-Za-z0-9]+)\", tweet)\n    count= len(user_names)\n    return count \n\n#average word length\ndef avg_word(tweet):\n    words = tweet.split()\n    return (sum(len(word) for word in words)/len(words))",
      "execution_count": 256,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Building the model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nxls = pd.ExcelFile('df_title_replaced.xlsx')\nneg_df = pd.read_excel(xls, 'neg')\npos_df = pd.read_excel(xls, 'pos')\nneu_df = pd.read_excel(xls, 'neu')",
      "execution_count": 257,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.utils import shuffle\nneg_df = shuffle(neg_df)\nprint(len(neg_df))\nprint(len(pos_df))\nprint(len(neu_df))\n",
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": "999\n1671\n3392\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "neg_df.reset_index(drop=True, inplace= True)\npos_df.reset_index(drop=True, inplace= True)\nneu_df.reset_index(drop=True, inplace= True)",
      "execution_count": 259,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "neg_train_df = neg_df[:900]\nneg_val_df = neg_df[900:]\npos_train_df = pos_df[:900]\npos_val_df = pos_df[900:1100]\nneu_train_df = neu_df[:900]\nneu_val_df = neu_df[900:1100]",
      "execution_count": 260,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_df = neg_train_df.append(pos_train_df, ignore_index= True)\ntrain_df = train_df.append(neu_train_df, ignore_index= True)",
      "execution_count": 261,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(train_df)",
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 262,
          "data": {
            "text/plain": "2700"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_df = neg_val_df.append(pos_val_df, ignore_index= True)\ntest_df = test_df.append(neu_val_df, ignore_index= True)",
      "execution_count": 263,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(test_df)",
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 264,
          "data": {
            "text/plain": "499"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = train_df.append(test_df, ignore_index= True)",
      "execution_count": 265,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "new_tweet_post = []\nfor article, tpost in zip(df.article_name, df.tweet_post):\n    new_post = fuzzy_place_3(article, \"stitlee\", tpost)\n    new_tweet_post.append(new_post)",
      "execution_count": 266,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['new_tweet_post'] = new_tweet_post",
      "execution_count": 267,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "df['new_tweet_post'].isnull().sum()",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#from textpreprocess import denoise_text, normalize, replace_contractions, remove_non_ascii, to_lowercase, remove_punctuation, replace_numbers, remove_stopwords, lemmatize_verbs\ndef preprocess(text):\n    text = replace_contractions(text)\n    content = nltk.word_tokenize(text)\n    words = remove_non_ascii(content)\n    words = to_lowercase(words)\n    words = lemmatize_verbs(words)#lemmatising verbs\n    #words = stem_words(words)\n    words = remove_punctuation(words)\n    words = replace_numbers(words)\n    #words = remove_stopwords(words)\n    text = ' '.join(words)\n    return text\n\n#Tried stemmer but didnt give good results lemmatising the words gave better results\n#tried tweets without changing their case but it wasnt either improving the model performance\n#lemmatisation of words and changing the case of words in tweets produced better results with svm",
      "execution_count": 268,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['Label'] = df['Label'].replace(['Neu'], 'Neutral')\ndf['Label'] = df['Label'].replace(['Neg','N'], 'Negative')\ndf['Label'] = df['Label'].replace(['Pos'], 'Positive')",
      "execution_count": 269,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['new_tweet_post'] = df['new_tweet_post'].apply(clean_tweet)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nltk.download('wordnet')\ndf['new_tweet_post'] = df['new_tweet_post'].apply(preprocess)",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package wordnet to /home/nbuser/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['Label'].value_counts()",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "Positive    1100\nNeutral     1100\nNegative     999\nName: Label, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_train = df[:2700]\ndf_test = df[2700:]",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train = df_train['new_tweet_post']\ny_train = df_train['Label']\nx_test = df_test['new_tweet_post']\ny_test = df_test['Label']",
      "execution_count": 105,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# from sklearn.model_selection import train_test_split\n# from sklearn import preprocessing\n# x_train, x_valid, y_train, y_valid = train_test_split(df_train['new_tweet_post'], df_train['Label'], \n#                                                                       random_state=2,test_size=0.05, stratify=df_train['Label'])",
      "execution_count": 106,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train.value_counts()",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 107,
          "data": {
            "text/plain": "Neutral     900\nPositive    900\nNegative    900\nName: Label, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_test.value_counts()",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 108,
          "data": {
            "text/plain": "Positive    200\nNeutral     200\nNegative     99\nName: Label, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)",
      "execution_count": 109,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\ncount_vec = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,2))\nxtrain_count = count_vec.fit_transform(x_train)\nxtest_count = count_vec.transform(x_test)",
      "execution_count": 110,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(xtrain_count.shape)\nprint(y_train.shape)\nprint(xtest_count.shape)\nprint(y_test.shape)",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(2700, 21934)\n(2700,)\n(499, 21934)\n(499,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import naive_bayes\nclassifier = naive_bayes.MultinomialNB()\n",
      "execution_count": 112,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classifier.fit(xtrain_count, y_train)\npredictions = classifier.predict(xtest_count)",
      "execution_count": 113,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test, predictions)",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 114,
          "data": {
            "text/plain": "0.7915831663326653"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ncm = confusion_matrix(y_test, predictions)\ncm_df = pd.DataFrame(cm.T, index=classifier.classes_, columns=classifier.classes_)\ncm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": "True        0    1    2\nPredicted              \n0          86    8   31\n1           8  156   16\n2           5   36  153\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions))",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.69      0.87      0.77        99\n          1       0.87      0.78      0.82       200\n          2       0.79      0.77      0.78       200\n\navg / total       0.80      0.79      0.79       499\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import svm\nclassifier_svm = svm.SVC()",
      "execution_count": 117,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classifier_svm.fit(xtrain_count, y_train)\nsvm_predictions = classifier_svm.predict(xtest_count)",
      "execution_count": 118,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test,svm_predictions)",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 119,
          "data": {
            "text/plain": "0.6492985971943888"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,svm_predictions))",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.61      0.34      0.44        99\n          1       0.61      0.86      0.72       200\n          2       0.73      0.58      0.65       200\n\navg / total       0.66      0.65      0.63       499\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nclassifier_RF = RandomForestClassifier(n_estimators=100)",
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classifier_RF.fit(xtrain_count, y_train)\nRF_predictions = classifier_svm.predict(xtest_count)",
      "execution_count": 122,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test,RF_predictions)",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 123,
          "data": {
            "text/plain": "0.6492985971943888"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,RF_predictions))",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.61      0.34      0.44        99\n          1       0.61      0.86      0.72       200\n          2       0.73      0.58      0.65       200\n\navg / total       0.66      0.65      0.63       499\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn import svm\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n\npipeline = Pipeline([\n    ('vect', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=10000)),\n    ('clf', svm.SVC())\n])\n\n# binary in TfidfVectorizer(): if True, all non-zero term counts are set to 1. \n# This does not mean outputs will have only 0/1 values, only that the tf term in tf-idf is binary.\nparameters = {\n    'clf__kernel':('rbf','linear'),\n    'vect__max_df': (0.1, 0.25, 0.5, 0.75),\n    'vect__stop_words': ('english', None),\n    #'vect__lowercase': (True, False),\n    'vect__binary': (True, False),\n    #'vect__max_features': (5000, 10000),\n    'vect__ngram_range': ((1, 1), (1, 2)),\n    'vect__use_idf': (True, False),\n    'vect__norm': ('l1', 'l2', None),\n    \"clf__C\": [0.5, 1, 10, 100],\n    'clf__gamma': [1e-2, 1e-3, 1e-4]\n}\n\nif __name__ == \"__main__\":\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)\n    grid_search.fit(x_train, y_train)\n    print('Best score: %0.3f' % grid_search.best_score_)\n    print('Best parameters set:')\n    best_parameters = grid_search.best_estimator_.get_params()\n    #for param_name in sorted(parameters.keys()):\n     #   print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n    predictions_pip = grid_search.predict(x_test)\n    print('Accuracy:', accuracy_score(y_test, predictions_pip))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for param_name in sorted(parameters.keys()):\n    print('%r: %s' % (param_name, best_parameters[param_name]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Additional Features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['new_tweet_post'] = new_tweet_post",
      "execution_count": 118,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom collections import Counter\ndef additional_features(df):\n    #number of upper case words \n    df['number_of_uppercase'] = df['new_tweet_post'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n    #number of urls\n    #df['number_of_urls'] = df['tweet_post'].apply(lambda x: len(re.findall(r'https?://\\S+',str(x))))\n    #number of hashtags in a tweet\n    df['number_of_hashtags'] = df['tweet_post'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n    #number of negated context in a tweet\n    df['number_of_negation'] = df['new_tweet_post'].apply(negation)\n    #number of words in a tweet\n    #df['word_count'] = df['new_tweet_post'].apply(lambda x: len(str(x).split(\" \")))\n    #average word length\n    #df['avg_word_length'] = df['new_tweet_post'].apply(avg_word)\n    #number of negative word count\n    df['neg_count'] = df['new_tweet_post'].apply(neg_word_count)\n    #number of positive word count\n    df['pos_count']= df['new_tweet_post'].apply(pos_word_count)\n    #sum of overall_score \n    df['overall_score'] = df['new_tweet_post'].apply(overall_score)\n    #number of exclamation marks\n    df['Exclamation_count'] =  np.vectorize(count_occurences)('!',df['tweet_post'])\n    #number of question marks\n    df['question_mark_count'] =  np.vectorize(count_occurences)('?',df['tweet_post'])\n    #number of punctuations\n    #df['punc_count'] = df['new_tweet_post'].apply(punc_count)\n    #number of user mentions in tweet\n    df['user_mention_count'] = df['tweet_post'].apply(user_mention_count)\n    #count_emoticons\n    #df['pos_emo_count'] = df['tweet_post'].apply(pos_emo_count)\n    #df['neg_emo_count'] = df['tweet_post'].apply(neg_emo_count)\n    \n    df['new_tweet_post'] = df['new_tweet_post'].apply(clean_tweet)\n    df['new_tweet_post'] = df['new_tweet_post'].apply(preprocess)\n    \n    df['last_word_polarity'] = df['new_tweet_post'].apply(las_pol)#run this after preprocessing\n    #number of pos tagging do after preprocessing of the tweets\n    df['pos_POStag_count'] = df['new_tweet_post'].apply(pos_POStag_count)\n    df['neg_POStag_count'] = df['new_tweet_post'].apply(neg_POStag_count)\n    return df",
      "execution_count": 270,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df= additional_features(df)",
      "execution_count": 271,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['pos_POStag_count'].value_counts()",
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 272,
          "data": {
            "text/plain": "0    1389\n1    1194\n2     414\n3     146\n4      34\n5      17\n6       4\n8       1\nName: pos_POStag_count, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df['overall_score'].describe()",
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 273,
          "data": {
            "text/plain": "count    3199.000000\nmean        0.101282\nstd         1.143979\nmin        -4.000000\n25%         0.000000\n50%         0.000000\n75%         1.000000\nmax         7.000000\nName: overall_score, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_train = df[:2700]\ndf_test = df[2700:]",
      "execution_count": 274,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(df_train)",
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 275,
          "data": {
            "text/plain": "2700"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train = df_train[df_train.columns[15:]] \ny_train = df_train[df_train.columns[14]] ",
      "execution_count": 276,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_test = df_test[df_train.columns[15:]] \ny_test = df_test[df_train.columns[14]] ",
      "execution_count": 277,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train.value_counts()",
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 278,
          "data": {
            "text/plain": "Positive    900\nNegative    900\nNeutral     900\nName: Label, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)",
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(2700, 13)\n(2700,)\n(499, 13)\n(499,)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\nmms = MinMaxScaler()",
      "execution_count": 280,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def norm(x_train):\n    x_train[['number_of_uppercase','number_of_hashtags']] = mms.fit_transform(x_train[['number_of_uppercase','number_of_hashtags']])\n    x_train[['pos_emo_count','neg_emo_count','last_word_polarity']] = mms.fit_transform(x_train[['pos_emo_count','neg_emo_count','last_word_polarity']])\n    x_train[['user_mention_count','pos_POStag_count', 'neg_POStag_count']] = mms.fit_transform(x_train[['user_mention_count','pos_POStag_count', 'neg_POStag_count']])\n    x_train[['overall_score','Exclamation_count','question_mark_count']] = mms.fit_transform(x_train[['overall_score','Exclamation_count','question_mark_count']])\n    x_train[['number_of_negation','neg_count','pos_count']] = mms.fit_transform(x_train[['number_of_negation','neg_count','pos_count']])\n    return x_train",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train[['number_of_uppercase','number_of_hashtags']] = mms.fit_transform(x_train[['number_of_uppercase','number_of_hashtags']])\nx_train[['last_word_polarity']] = mms.fit_transform(x_train[['last_word_polarity']])\nx_train[['user_mention_count','pos_POStag_count', 'neg_POStag_count']] = mms.fit_transform(x_train[['user_mention_count','pos_POStag_count', 'neg_POStag_count']])\nx_train[['overall_score','Exclamation_count','question_mark_count']] = mms.fit_transform(x_train[['overall_score','Exclamation_count','question_mark_count']])\nx_train[['number_of_negation','neg_count','pos_count']] = mms.fit_transform(x_train[['number_of_negation','neg_count','pos_count']])",
      "execution_count": 281,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_test[['number_of_uppercase','number_of_hashtags']] = mms.fit_transform(x_test[['number_of_uppercase','number_of_hashtags']])\nx_test[['last_word_polarity']] = mms.fit_transform(x_test[['last_word_polarity']])\nx_test[['user_mention_count','pos_POStag_count', 'neg_POStag_count']] = mms.fit_transform(x_test[['user_mention_count','pos_POStag_count', 'neg_POStag_count']])\nx_test[['overall_score','Exclamation_count','question_mark_count']] = mms.fit_transform(x_test[['overall_score','Exclamation_count','question_mark_count']])\nx_test[['number_of_negation','neg_count','pos_count']] = mms.fit_transform(x_test[['number_of_negation','neg_count','pos_count']])",
      "execution_count": 282,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train['overall_score'].describe()",
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 283,
          "data": {
            "text/plain": "count    2700.000000\nmean        0.372256\nstd         0.105512\nmin         0.000000\n25%         0.363636\n50%         0.363636\n75%         0.454545\nmax         1.000000\nName: overall_score, dtype: float64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)",
      "execution_count": 284,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "le_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\nprint(le_name_mapping)",
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'Neutral': 1, 'Negative': 0, 'Positive': 2}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "x_train.columns",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 136,
          "data": {
            "text/plain": "Index(['new_tweet_post', 'number_of_uppercase', 'number_of_hashtags',\n       'number_of_negation', 'neg_count', 'pos_count', 'overall_score',\n       'Exclamation_count', 'question_mark_count', 'user_mention_count',\n       'pos_emo_count', 'neg_emo_count', 'last_word_polarity',\n       'pos_POStag_count', 'neg_POStag_count'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using TF-IDF vectoriser with additional features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn_pandas import DataFrameMapper\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nmapper = DataFrameMapper([\n     ('new_tweet_post',TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',ngram_range=(1,2), max_df=0.5, norm='l2')),\n     ('number_of_uppercase', None),\n#      ('number_of_urls',None),\n     ('number_of_hashtags',None),\n     ('number_of_negation',None),\n     ('neg_count',None),\n     ('pos_count',None),\n     ('overall_score',None),\n     ('Exclamation_count',None),\n     ('question_mark_count',None),\n#      ('punc_count',None),\n     ('user_mention_count',None),\n     ('neg_POStag_count',None),\n     ('pos_POStag_count',None),\n     ('pos_emo_count',None),\n     ('neg_emo_count',None),\n#    ('word_count', None),\n    ('last_word_polarity',None),\n    #('avg_word_length', None)\n])",
      "execution_count": 105,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train.columns",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 106,
          "data": {
            "text/plain": "Index(['new_tweet_post', 'number_of_uppercase', 'number_of_hashtags',\n       'number_of_negation', 'neg_count', 'pos_count', 'overall_score',\n       'Exclamation_count', 'question_mark_count', 'user_mention_count',\n       'pos_emo_count', 'neg_emo_count', 'last_word_polarity',\n       'pos_POStag_count', 'neg_POStag_count'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "xn_train = mapper.fit_transform(x_train)\nxn_test = mapper.transform(x_test)",
      "execution_count": 107,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# naive-bayes"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import naive_bayes\nclassifier = naive_bayes.MultinomialNB()\n",
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classifier.fit(xn_train, y_train)\npredictions_1 = classifier.predict(xn_test)",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test, predictions_1)",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": "0.8196392785571143"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ncm = confusion_matrix(y_test, predictions_1)\ncm_df = pd.DataFrame(cm.T, index=classifier.classes_, columns=classifier.classes_)\ncm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)\n\n",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": "True        0    1    2\nPredicted              \n0          88    6   18\n1           4  151   11\n2           7   43  171\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions_1))",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.79      0.89      0.83        99\n          1       0.91      0.76      0.83       200\n          2       0.77      0.85      0.81       200\n\navg / total       0.83      0.82      0.82       499\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Random forest"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nclassifier_RF = RandomForestClassifier(n_estimators=100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "classifier_RF.fit(x_train, y_train)\npredictions = classifier_RF.predict(x_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test, predictions)",
      "execution_count": 91,
      "outputs": [
        {
          "data": {
            "text/plain": "0.779559118236473"
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions))",
      "execution_count": 92,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.66      0.88      0.76        99\n          1       0.81      0.80      0.80       200\n          2       0.84      0.71      0.77       200\n\navg / total       0.79      0.78      0.78       499\n\n"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# SVM"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "from sklearn import svm\nclassifier_svm = svm.SVC(kernel='linear')"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "classifier_svm.fit(xn_train, y_train)\npredictions_2 = classifier_svm.predict(xn_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test, predictions_2)",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 110,
          "data": {
            "text/plain": "0.8637274549098196"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ncm = confusion_matrix(y_test, predictions_2)\ncm_df = pd.DataFrame(cm.T, index=classifier_svm.classes_, columns=classifier_svm.classes_)\ncm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": "True        0    1    2\nPredicted              \n0          90   11   15\n1           4  166   10\n2           5   23  175\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions_2))",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.76      0.85      0.80        99\n          1       0.91      0.81      0.86       200\n          2       0.82      0.86      0.84       200\n\navg / total       0.84      0.84      0.84       499\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Using count vectoriser along with dataframe mapper"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn_pandas import DataFrameMapper\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nmapper = DataFrameMapper([\n     ('new_tweet_post',CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1,1))),\n     ('number_of_uppercase', None),\n#      ('number_of_urls',None),\n     ('number_of_hashtags',None),\n     ('number_of_negation',None),\n     ('neg_count',None),\n     ('pos_count',None),\n     ('overall_score',None),\n     ('Exclamation_count',None),\n     ('question_mark_count',None),\n#      ('punc_count',None),\n     ('user_mention_count',None),\n     ('neg_POStag_count',None),\n     ('pos_POStag_count',None),\n     ('pos_emo_count',None),\n     ('neg_emo_count',None),\n#    ('word_count', None),\n    ('last_word_polarity',None),\n    #('avg_word_length', None)\n])",
      "execution_count": 114,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "x_train = mapper.fit_transform(x_train)\nx_test = mapper.transform(x_test)",
      "execution_count": 115,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn import naive_bayes\nclassifier = naive_bayes.MultinomialNB()\nclassifier.fit(x_train, y_train)\npredictions_1 = classifier.predict(x_test)\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test, predictions_1)",
      "execution_count": 103,
      "outputs": [
        {
          "data": {
            "text/plain": "0.811623246492986"
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions_1))",
      "execution_count": 104,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.71      0.93      0.80        99\n          1       0.91      0.78      0.84       200\n          2       0.79      0.79      0.79       200\n\navg / total       0.82      0.81      0.81       499\n\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import svm\nclassifier_svm = svm.SVC(kernel='linear')\nclassifier_svm.fit(x_train, y_train)\npredictions_3 = classifier_svm.predict(x_test)\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\naccuracy_score(y_test, predictions_3)",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 116,
          "data": {
            "text/plain": "0.8496993987975952"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(classification_report(y_test,predictions_2))",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": "             precision    recall  f1-score   support\n\n          0       0.78      0.91      0.84        99\n          1       0.92      0.83      0.87       200\n          2       0.86      0.88      0.87       200\n\navg / total       0.87      0.86      0.86       499\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Pipeline for addtional features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.base import BaseEstimator, TransformerMixin\n\nclass TextSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to select a single column from the data frame to perform additional transformations on\n    Use on text columns in the data\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None): # fit() doesn't do anything\n        return self\n\n    def transform(self, X):   # all the work is done here\n        return X[self.key]\n    \nclass NumberSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Transformer to select a single column from the data frame to perform additional transformations on\n    Use on numeric columns in the data\n    \"\"\"\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]\n",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\n\nnew_tweet_post = Pipeline([\n                ('selector', TextSelector(key='new_tweet_post')),\n                ('tfidf', TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}',ngram_range=(1,2), max_df=0.5, norm='l2'))\n            ])\n\nnumber_of_uppercase =  Pipeline([\n                ('selector', NumberSelector(key='number_of_uppercase')),\n                ('standard', MinMaxScaler())\n            ])\n#number_of_urls =  Pipeline([\n#                 ('selector', NumberSelector(key='number_of_urls')),\n#                 ('standard', MinMaxScaler())\n#             ])\nnumber_of_hashtags =  Pipeline([\n                ('selector', NumberSelector(key='number_of_hashtags')),\n                ('standard', MinMaxScaler())\n            ])\nnumber_of_negation =  Pipeline([\n                ('selector', NumberSelector(key='number_of_negation')),\n                ('standard', MinMaxScaler())\n            ])\nneg_count =  Pipeline([\n                ('selector', NumberSelector(key='neg_count')),\n                ('standard', MinMaxScaler())\n            ])\npos_count =  Pipeline([\n                ('selector', NumberSelector(key='pos_count')),\n                ('standard', MinMaxScaler())\n            ])\noverall_score =  Pipeline([\n                ('selector', NumberSelector(key='overall_score')),\n                ('standard', MinMaxScaler())\n            ])\nExclamation_count =  Pipeline([\n                ('selector', NumberSelector(key='Exclamation_count')),\n                ('standard', MinMaxScaler())\n            ])\nquestion_mark_count =  Pipeline([\n                ('selector', NumberSelector(key='question_mark_count')),\n                ('standard', MinMaxScaler())\n            ])\nuser_mention_count =  Pipeline([\n                ('selector', NumberSelector(key='user_mention_count')),\n                ('standard', MinMaxScaler())\n            ])\npos_emo_count =  Pipeline([\n                ('selector', NumberSelector(key='pos_emo_count')),\n                ('standard', MinMaxScaler())\n            ])\nneg_emo_count =  Pipeline([\n                ('selector', NumberSelector(key='neg_emo_count')),\n                ('standard', MinMaxScaler())\n            ])\nlast_word_polarity =  Pipeline([\n                ('selector', NumberSelector(key='last_word_polarity')),\n                ('standard', MinMaxScaler())\n            ])\npos_POStag_count =  Pipeline([\n                ('selector', NumberSelector(key='pos_POStag_count')),\n                ('standard', MinMaxScaler())\n            ])\nneg_POStag_count =  Pipeline([\n                ('selector', NumberSelector(key='neg_POStag_count')),\n                ('standard', MinMaxScaler())\n            ])",
      "execution_count": 114,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.pipeline import FeatureUnion\n\nfeats = FeatureUnion([('new_tweet_post', new_tweet_post), \n                      ('number_of_uppercase', number_of_uppercase),\n                      #('number_of_urls', number_of_urls),\n                      ('number_of_hashtags', number_of_hashtags),\n                      ('number_of_negation', number_of_negation),\n                      ('neg_count', neg_count),\n                      ('pos_count', pos_count),\n                      ('overall_score', overall_score),\n                      ('Exclamation_count', Exclamation_count),\n                      ('question_mark_count', question_mark_count),\n                      ('user_mention_count', user_mention_count),\n                      ('pos_emo_count', pos_emo_count),\n                      ('neg_emo_count', neg_emo_count),\n                      ('last_word_polarity', last_word_polarity),\n                      ('pos_POStag_count', pos_POStag_count),\n                      ('neg_POStag_count', neg_POStag_count)])\n\nfeature_processing = Pipeline([('feats', feats)])\nfeature_processing.fit_transform(x_train) ",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 115,
          "data": {
            "text/plain": "<2700x21965 sparse matrix of type '<class 'numpy.float64'>'\n\twith 79739 stored elements in Compressed Sparse Row format>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "feature_processing.transform(x_test)",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 116,
          "data": {
            "text/plain": "<499x21965 sparse matrix of type '<class 'numpy.float64'>'\n\twith 10568 stored elements in Compressed Sparse Row format>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn import svm\n\npipeline = Pipeline([\n    ('features',feats),\n    ('classifier', svm.SVC(kernel='linear'))\n])",
      "execution_count": 120,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ny_train = encoder.fit_transform(y_train)\ny_test = encoder.transform(y_test)",
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipeline.fit(x_train, y_train)\npreds = pipeline.predict(x_test)\nnp.mean(preds == y_test)",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 122,
          "data": {
            "text/plain": "0.8637274549098196"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ncm = confusion_matrix(y_test, predictions_1)\ncm_df = pd.DataFrame(cm.T, index=classifier.classes_, columns=classifier.classes_)\ncm_df.index.name = 'Predicted'\ncm_df.columns.name = 'True'\nprint(cm_df)",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": "True        0    1    2\nPredicted              \n0          88    6   18\n1           4  151   11\n2           7   43  171\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "pipeline.get_params().keys()",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": "dict_keys(['features__new_tweet_post__tfidf__min_df', 'features__question_mark_count', 'features__pos_count__standard__copy', 'features__user_mention_count__selector', 'features__user_mention_count__standard', 'features__pos_emo_count__standard', 'features__number_of_negation', 'features__Exclamation_count__standard__copy', 'features__new_tweet_post__tfidf__smooth_idf', 'features__neg_POStag_count__standard', 'features__new_tweet_post__selector__key', 'features__neg_emo_count__memory', 'features__pos_POStag_count__standard__feature_range', 'features__pos_count__selector', 'classifier__tol', 'features__new_tweet_post', 'features__number_of_hashtags__standard__copy', 'features__question_mark_count__standard__copy', 'features__overall_score__selector', 'features__number_of_hashtags__steps', 'classifier__degree', 'features__pos_emo_count__selector__key', 'features__number_of_negation__selector', 'classifier__max_iter', 'features__user_mention_count__steps', 'memory', 'features__neg_count__standard__feature_range', 'features__neg_count__standard__copy', 'features__last_word_polarity__standard', 'features__new_tweet_post__tfidf', 'features__new_tweet_post__tfidf__preprocessor', 'features__neg_count__memory', 'features__new_tweet_post__tfidf__binary', 'features__question_mark_count__selector', 'features__number_of_uppercase__standard__feature_range', 'features__overall_score', 'features__new_tweet_post__tfidf__ngram_range', 'features__number_of_negation__selector__key', 'classifier__decision_function_shape', 'features__last_word_polarity__selector', 'features__neg_count__selector', 'features__overall_score__steps', 'features__neg_count__steps', 'features__new_tweet_post__tfidf__strip_accents', 'features__Exclamation_count__selector__key', 'features__number_of_hashtags__standard', 'features__overall_score__standard__feature_range', 'features__neg_emo_count__steps', 'features__new_tweet_post__tfidf__max_df', 'classifier__random_state', 'features__Exclamation_count__standard', 'features__overall_score__standard__copy', 'features__new_tweet_post__tfidf__dtype', 'features__pos_emo_count__selector', 'classifier__verbose', 'features__number_of_negation__memory', 'features__last_word_polarity__standard__copy', 'features__question_mark_count__memory', 'features__new_tweet_post__steps', 'features__Exclamation_count__standard__feature_range', 'features__neg_POStag_count__selector__key', 'features__pos_count__standard', 'features__new_tweet_post__tfidf__token_pattern', 'features__new_tweet_post__tfidf__lowercase', 'features__new_tweet_post__tfidf__input', 'features__Exclamation_count__selector', 'features__last_word_polarity__selector__key', 'features__new_tweet_post__selector', 'features__pos_count__steps', 'features__number_of_uppercase', 'features__pos_POStag_count__selector', 'features__number_of_negation__standard', 'features__question_mark_count__steps', 'features__new_tweet_post__tfidf__decode_error', 'classifier__C', 'features__new_tweet_post__tfidf__tokenizer', 'features__pos_count', 'classifier', 'classifier__probability', 'features__number_of_uppercase__standard', 'features__last_word_polarity__memory', 'classifier__class_weight', 'features__neg_POStag_count__steps', 'features__pos_emo_count__steps', 'features__overall_score__standard', 'features__number_of_negation__standard__copy', 'features__neg_POStag_count__standard__copy', 'features__Exclamation_count__memory', 'features__pos_POStag_count__standard', 'features__user_mention_count__standard__copy', 'features__neg_emo_count', 'features__transformer_list', 'features__pos_count__standard__feature_range', 'features__pos_POStag_count__standard__copy', 'features__pos_count__memory', 'features__pos_emo_count__standard__feature_range', 'features__Exclamation_count', 'features__pos_POStag_count__steps', 'features__number_of_negation__steps', 'features__pos_emo_count__standard__copy', 'features__new_tweet_post__tfidf__norm', 'features__new_tweet_post__tfidf__stop_words', 'features__neg_emo_count__standard__copy', 'features__number_of_hashtags__selector', 'classifier__cache_size', 'features__overall_score__selector__key', 'features__question_mark_count__standard', 'features__neg_emo_count__selector__key', 'features__neg_count__standard', 'features__neg_count__selector__key', 'features__neg_POStag_count__selector', 'features__user_mention_count__memory', 'features__n_jobs', 'features__number_of_uppercase__steps', 'classifier__shrinking', 'features__neg_POStag_count__standard__feature_range', 'features__neg_emo_count__standard__feature_range', 'features__number_of_hashtags__standard__feature_range', 'features__new_tweet_post__tfidf__use_idf', 'classifier__coef0', 'features__pos_POStag_count__selector__key', 'features__number_of_uppercase__standard__copy', 'features__overall_score__memory', 'features__new_tweet_post__tfidf__analyzer', 'features__number_of_uppercase__selector__key', 'features__pos_emo_count', 'features__pos_count__selector__key', 'features__Exclamation_count__steps', 'features__user_mention_count__selector__key', 'features__pos_emo_count__memory', 'features__number_of_uppercase__memory', 'features__new_tweet_post__tfidf__vocabulary', 'features__user_mention_count__standard__feature_range', 'features__number_of_hashtags__memory', 'features__number_of_negation__standard__feature_range', 'features__user_mention_count', 'features__last_word_polarity__standard__feature_range', 'features__number_of_hashtags', 'features__neg_emo_count__standard', 'features__neg_emo_count__selector', 'features__transformer_weights', 'features__last_word_polarity', 'features__new_tweet_post__tfidf__encoding', 'features__new_tweet_post__memory', 'features__neg_POStag_count', 'features__pos_POStag_count__memory', 'features', 'features__question_mark_count__standard__feature_range', 'features__new_tweet_post__tfidf__max_features', 'features__question_mark_count__selector__key', 'features__neg_POStag_count__memory', 'classifier__gamma', 'features__new_tweet_post__tfidf__sublinear_tf', 'steps', 'features__pos_POStag_count', 'classifier__kernel', 'features__neg_count', 'features__last_word_polarity__steps', 'features__number_of_hashtags__selector__key', 'features__number_of_uppercase__selector'])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV\n\nhyperparameters = { 'features__new_tweet_post__tfidf__max_df': [0.5, 0.75],\n                   'features__new_tweet_post__tfidf__norm':('l1', 'l2'),\n                   #'features__new_tweet_post__tfidf__stop_words':('english', None),\n                    'features__new_tweet_post__tfidf__ngram_range': [(1,1), (1,2)],\n                   #'features__new_tweet_post__tfidf__binary':(True,False),\n                   #'features__new_tweet_post__tfidf__use_idf':(True,False),\n                    'classifier__C': (0.5, 1, 10),\n                    'classifier__gamma': (1e-2, 1e-3),\n                    'classifier__kernel': ('linear', 'rbf')\n                  }\nclf = GridSearchCV(pipeline, hyperparameters, cv=3)",
      "execution_count": 110,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Fit and tune model\nclf.fit(x_train, y_train)",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 111,
          "data": {
            "text/plain": "GridSearchCV(cv=3, error_score='raise',\n       estimator=Pipeline(memory=None,\n     steps=[('features', FeatureUnion(n_jobs=1,\n       transformer_list=[('new_tweet_post', Pipeline(memory=None,\n     steps=[('selector', TextSelector(key='new_tweet_post')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='ut...,\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False))]),\n       fit_params=None, iid=True, n_jobs=1,\n       param_grid={'features__new_tweet_post__tfidf__ngram_range': [(1, 1), (1, 2)], 'classifier__kernel': ('linear', 'rbf'), 'features__new_tweet_post__tfidf__norm': ('l1', 'l2'), 'classifier__C': (0.5, 1, 10), 'features__new_tweet_post__tfidf__max_df': [0.5, 0.75], 'classifier__gamma': (0.01, 0.001)},\n       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n       scoring=None, verbose=0)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "preds_2 = clf.predict(x_test)\nnp.mean(preds == y_test)",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 113,
          "data": {
            "text/plain": "0.8176352705410822"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "clf.best_params_",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 112,
          "data": {
            "text/plain": "{'classifier__C': 1,\n 'classifier__gamma': 0.01,\n 'classifier__kernel': 'linear',\n 'features__new_tweet_post__tfidf__max_df': 0.5,\n 'features__new_tweet_post__tfidf__ngram_range': (1, 1),\n 'features__new_tweet_post__tfidf__norm': 'l2'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# testing the model on another set of files"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pos_val_df2 = pos_df[1100:]\nneu_val_df2 = neu_df[1100:]",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_2 = neu_val_df2.append(pos_val_df2, ignore_index= True)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "len(df_2)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "2863"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "new_tweet_post = []\nfor article, tpost in zip(df_2.article_name, df_2.tweet_post):\n    new_post = fuzzy_place_3(article, \"stitlee\", tpost)\n    new_tweet_post.append(new_post)",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_2['Label'] = df_2['Label'].replace(['Neu'], 'Neutral')\ndf_2['Label'] = df_2['Label'].replace(['Neg','N'], 'Negative')\ndf_2['Label'] = df_2['Label'].replace(['Pos'], 'Positive')",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_2['Label'].value_counts()",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "Neutral     2292\nPositive     571\nName: Label, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_2['new_tweet_post'] = new_tweet_post",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_2 = additional_features(df_2)",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_2.columns",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": "Index(['citation', 'altid', 'count', 'profile_link', 'profile_name',\n       'display_name', 'tweet_post', 'post_time', 'post_URL', 'article_name',\n       'Language', 'sentiment', 'subjectivity', 'polarity', 'Label',\n       'new_tweet_post', 'number_of_uppercase', 'number_of_hashtags',\n       'number_of_negation', 'neg_count', 'pos_count', 'overall_score',\n       'Exclamation_count', 'question_mark_count', 'user_mention_count',\n       'pos_emo_count', 'neg_emo_count', 'last_word_polarity',\n       'pos_POStag_count', 'neg_POStag_count'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df_train.columns\n  ",
      "execution_count": 400,
      "outputs": [
        {
          "data": {
            "text/plain": "Index(['citation', 'altid', 'count', 'profile_link', 'profile_name',\n       'display_name', 'tweet_post', 'post_time', 'post_URL', 'article_name',\n       'Language', 'sentiment', 'subjectivity', 'polarity', 'Label',\n       'new_tweet_post', 'number_of_uppercase', 'number_of_urls',\n       'number_of_hashtags', 'number_of_negation', 'neg_count', 'pos_count',\n       'overall_score', 'Exclamation_count', 'question_mark_count',\n       'user_mention_count', 'pos_emo_count', 'neg_emo_count',\n       'last_word_polarity', 'pos_POStag_count', 'neg_POStag_count'],\n      dtype='object')"
          },
          "execution_count": 400,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn import svm\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n\npipeline = Pipeline([\n    ('vect', mapper),\n    ('clf', svm.SVC())\n])\nparameters = {'clf__kernel':['']\n    \"clf__C\": [0.1, 1, 10, 100],\n    'clf__gamma': [1e-2, 1e-3, 1e-4]\n}",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "if __name__ == \"__main__\":\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)\n    grid_search.fit(x_train, y_train)\n    print('Best score: %0.3f' % grid_search.best_score_)\n    print('Best parameters set:')\n    best_parameters = grid_search.best_estimator_.get_params()\n    #for param_name in sorted(parameters.keys()):\n     #   print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n    predictions = grid_search.predict(x_test)\n    print('Accuracy:', accuracy_score(y_test, predictions))",
      "execution_count": 52,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
        },
        {
          "ename": "JoblibIndexError",
          "evalue": "JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x01F55440, file \"C:\\Us...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x01F55440, file \"C:\\Us...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(340, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(340, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (340, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=340, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 8, 36, 24, 323722, tzinfo=tzutc()), 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'session': '9a89fd109ead475682fddc7b9f263ebf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'9a89fd109ead475682fddc7b9f263ebf']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 8, 36, 24, 323722, tzinfo=tzutc()), 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'session': '9a89fd109ead475682fddc7b9f263ebf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'9a89fd109ead475682fddc7b9f263ebf'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 8, 36, 24, 323722, tzinfo=tzutc()), 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'session': '9a89fd109ead475682fddc7b9f263ebf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.If object>], cell_name='<ipython-input-52-d9eff0b324cd>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 10b952b0, execution_c...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x10C906A8, file \"<ipython-input-52-d9eff0b324cd>\", line 1>\n        result = <ExecutionResult object at 10b952b0, execution_c...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x10C906A8, file \"<ipython-input-52-d9eff0b324cd>\", line 1>, result=<ExecutionResult object at 10b952b0, execution_c...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x10C906A8, file \"<ipython-input-52-d9eff0b324cd>\", line 1>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#removing the altmeric word in article name\\ndef ...e_name = ' '.join(a)\\n    return article_name\\n    \", 'from fuzzywuzzy import fuzz\\n#replacing the tile ...           print(text)\\n    return text\\n    \\n     ', 'from fuzzywuzzy import fuzz\\nimport warnings\\nwarn...           print(text)\\n    return text\\n    \\n     ', 'def fuzzy_place_3(str_a, str_b, orig_str):\\n    t...   \\n                    \\n    return text\\n        ', 'import re\\nfrom fuzzywuzzy import fuzz', \"#negation count function\\nimport nltk\\nimport nltk...en(re.findall('\\\\w+_NEG', tweet))\\n    return count\", '#number of negative words in a tweet\\ndef neg_wor...       \\n            except: pass\\n    return count', '#no of positive words in a tweet\\ndef pos_word_co...       \\n            except: pass\\n    return count', '#overall score of the tweet\\ndef overall_score(tw...   except: \\n                pass\\n    return score', '#number of adjectives, adverbs and verbs in a tw...cept: pass        \\n    return count              ', '# creating the function to calculate the emotico...   #print(neg_emo_count)\\n    return neg_emo_count', '#count occurences of a ! and ?\\ndef count_occuren...         counter += 1\\n\\n            return counter', '#punctuation count\\nimport string\\ndef punc_count(...t(string.punctuation))\\n    return punct\\n    \\n    ', '# count number of user name mentions\\ndef user_me...weet)\\n    count= len(user_names)\\n    return count', \"import pandas as pd\\nxls = pd.ExcelFile('/Users/S...el(xls, 'pos')\\nneu_df = pd.read_excel(xls, 'neu')\", 'print(len(neg_df))\\nprint(len(pos_df))\\nprint(len(neu_df))', 'neg_df.reset_index(drop=True, inplace= True)\\npos...rue)\\nneu_df.reset_index(drop=True, inplace= True)', 'neg_train_df = neg_df[:800]\\nneg_val_df = neg_df[...n_df = neu_df[:900]\\nneu_val_df = neu_df[900:1100]', 'train_df = neg_train_df.append(pos_train_df, ign...train_df.append(neu_train_df, ignore_index= True)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {20: 2600, 22: 449, 26: 3049, 29: Positive    1100\nNeutral     1100\nNegative     849\nName: Label, dtype: int64, 39: count    3049.000000\nmean        9.824205\nstd   ...2.000000\nName: user_mention_count, dtype: float64, 42: 2600}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#removing the altmeric word in article name\\ndef ...e_name = ' '.join(a)\\n    return article_name\\n    \", 'from fuzzywuzzy import fuzz\\n#replacing the tile ...           print(text)\\n    return text\\n    \\n     ', 'from fuzzywuzzy import fuzz\\nimport warnings\\nwarn...           print(text)\\n    return text\\n    \\n     ', 'def fuzzy_place_3(str_a, str_b, orig_str):\\n    t...   \\n                    \\n    return text\\n        ', 'import re\\nfrom fuzzywuzzy import fuzz', \"#negation count function\\nimport nltk\\nimport nltk...en(re.findall('\\\\w+_NEG', tweet))\\n    return count\", '#number of negative words in a tweet\\ndef neg_wor...       \\n            except: pass\\n    return count', '#no of positive words in a tweet\\ndef pos_word_co...       \\n            except: pass\\n    return count', '#overall score of the tweet\\ndef overall_score(tw...   except: \\n                pass\\n    return score', '#number of adjectives, adverbs and verbs in a tw...cept: pass        \\n    return count              ', '# creating the function to calculate the emotico...   #print(neg_emo_count)\\n    return neg_emo_count', '#count occurences of a ! and ?\\ndef count_occuren...         counter += 1\\n\\n            return counter', '#punctuation count\\nimport string\\ndef punc_count(...t(string.punctuation))\\n    return punct\\n    \\n    ', '# count number of user name mentions\\ndef user_me...weet)\\n    count= len(user_names)\\n    return count', \"import pandas as pd\\nxls = pd.ExcelFile('/Users/S...el(xls, 'pos')\\nneu_df = pd.read_excel(xls, 'neu')\", 'print(len(neg_df))\\nprint(len(pos_df))\\nprint(len(neu_df))', 'neg_df.reset_index(drop=True, inplace= True)\\npos...rue)\\nneu_df.reset_index(drop=True, inplace= True)', 'neg_train_df = neg_df[:800]\\nneg_val_df = neg_df[...n_df = neu_df[:900]\\nneu_val_df = neu_df[900:1100]', 'train_df = neg_train_df.append(pos_train_df, ign...train_df.append(neu_train_df, ignore_index= True)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {20: 2600, 22: 449, 26: 3049, 29: Positive    1100\nNeutral     1100\nNegative     849\nName: Label, dtype: int64, 39: count    3049.000000\nmean        9.824205\nstd   ...2.000000\nName: user_mention_count, dtype: float64, 42: 2600}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Sarath\\<ipython-input-52-d9eff0b324cd> in <module>()\n      1 if __name__ == \"__main__\":\n      2     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)\n----> 3     grid_search.fit(x_train, y_train)\n      4     print('Best score: %0.3f' % grid_search.best_score_)\n      5     print('Best parameters set:')\n      6     best_parameters = grid_search.best_estimator_.get_params()\n      7     #for param_name in sorted(parameters.keys()):\n      8      #   print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n      9     predictions = grid_search.predict(x_test)\n     10     print('Accuracy:', accuracy_score(y_test, predictions))\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ore='warn',\n       scoring='accuracy', verbose=1), X=array([[0.        , 0.        , 0.        , ...,....., 0.        , 0.        ,\n        0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int32), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[0.        , 0.        , 0.        , ...,....., 0.        , 0.        ,\n        0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int32)\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Thu Mar 28 16:37:25 2019\nPID: 10388               Python 3.6.5: C:\\Users\\Sarath\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 267,  268,  269, ..., 2597, 2598, 2599]), test=array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), verbose=1, parameters={'clf__C': 0.1, 'clf__gamma': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y_train = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x0D17C348>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1])), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]))\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), weight=None, X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method DataFrameMapper.fit_transform of D...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]))\n    383 \n    384         X       the data to fit\n    385 \n    386         y       the target vector relative to X, optional\n    387         \"\"\"\n--> 388         return self._transform(X, y, True)\n        self._transform = <bound method DataFrameMapper._transform of Data...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), do_fit=True)\n    293             input_df = options.get('input_df', self.input_df)\n    294 \n    295             # columns could be a string or list of\n    296             # strings; we don't care because pandas\n    297             # will handle either.\n--> 298             Xt = self._get_col_subset(X, columns, input_df)\n        Xt = undefined\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        columns = 'new_tweet_post'\n        input_df = False\n    299             if transformers is not None:\n    300                 with add_column_names_to_exception(columns):\n    301                     if do_fit and hasattr(transformers, 'fit_transform'):\n    302                         Xt = _call_fit(transformers.fit_transform, Xt, y)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _get_col_subset(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), cols=['new_tweet_post'], input_df=False)\n    187 \n    188         elif isinstance(X, DataWrapper):\n    189             X = X.df  # fetch underlying data\n    190 \n    191         if return_vector:\n--> 192             t = X[cols[0]]\n        t = undefined\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        cols = ['new_tweet_post']\n    193         else:\n    194             t = X[cols]\n    195 \n    196         # return either a DataFrame/Series or a numpy array\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py in __getitem__(self=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), index='new_tweet_post')\n    326             return arr[()]\n    327         # Return ndarray otherwise\n    328         return arr.view(np.ndarray)\n    329 \n    330     def __getitem__(self, index):\n--> 331         res = super(memmap, self).__getitem__(index)\n        res = undefined\n        self.__getitem__ = <bound method memmap.__getitem__ of memmap([[0. ..., 0.        , 0.        ,\n         0.        ]])>\n        index = 'new_tweet_post'\n    332         if type(res) is memmap and res._mmap is None:\n    333             return res.view(type=ndarray)\n    334         return res\n\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n___________________________________________________________________________",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 248, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 213, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 388, in fit_transform\n    return self._transform(X, y, True)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 298, in _transform\n    Xt = self._get_col_subset(X, columns, input_df)\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 192, in _get_col_subset\n    t = X[cols[0]]\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py\", line 331, in __getitem__\n    res = super(memmap, self).__getitem__(index)\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nIndexError                                         Thu Mar 28 16:37:25 2019\nPID: 10388               Python 3.6.5: C:\\Users\\Sarath\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 267,  268,  269, ..., 2597, 2598, 2599]), test=array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), verbose=1, parameters={'clf__C': 0.1, 'clf__gamma': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y_train = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x0D17C348>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1])), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]))\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), weight=None, X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method DataFrameMapper.fit_transform of D...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]))\n    383 \n    384         X       the data to fit\n    385 \n    386         y       the target vector relative to X, optional\n    387         \"\"\"\n--> 388         return self._transform(X, y, True)\n        self._transform = <bound method DataFrameMapper._transform of Data...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), do_fit=True)\n    293             input_df = options.get('input_df', self.input_df)\n    294 \n    295             # columns could be a string or list of\n    296             # strings; we don't care because pandas\n    297             # will handle either.\n--> 298             Xt = self._get_col_subset(X, columns, input_df)\n        Xt = undefined\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        columns = 'new_tweet_post'\n        input_df = False\n    299             if transformers is not None:\n    300                 with add_column_names_to_exception(columns):\n    301                     if do_fit and hasattr(transformers, 'fit_transform'):\n    302                         Xt = _call_fit(transformers.fit_transform, Xt, y)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _get_col_subset(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), cols=['new_tweet_post'], input_df=False)\n    187 \n    188         elif isinstance(X, DataWrapper):\n    189             X = X.df  # fetch underlying data\n    190 \n    191         if return_vector:\n--> 192             t = X[cols[0]]\n        t = undefined\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        cols = ['new_tweet_post']\n    193         else:\n    194             t = X[cols]\n    195 \n    196         # return either a DataFrame/Series or a numpy array\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py in __getitem__(self=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), index='new_tweet_post')\n    326             return arr[()]\n    327         # Return ndarray otherwise\n    328         return arr.view(np.ndarray)\n    329 \n    330     def __getitem__(self, index):\n--> 331         res = super(memmap, self).__getitem__(index)\n        res = undefined\n        self.__getitem__ = <bound method memmap.__getitem__ of memmap([[0. ..., 0.        , 0.        ,\n         0.        ]])>\n        index = 'new_tweet_post'\n    332         if type(res) is memmap and res._mmap is None:\n    333             return res.view(type=ndarray)\n    334         return res\n\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n___________________________________________________________________________\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nIndexError                                         Thu Mar 28 16:37:25 2019\nPID: 10388               Python 3.6.5: C:\\Users\\Sarath\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 267,  268,  269, ..., 2597, 2598, 2599]), test=array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), verbose=1, parameters={'clf__C': 0.1, 'clf__gamma': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y_train = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x0D17C348>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1])), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]))\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), weight=None, X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method DataFrameMapper.fit_transform of D...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]))\n    383 \n    384         X       the data to fit\n    385 \n    386         y       the target vector relative to X, optional\n    387         \"\"\"\n--> 388         return self._transform(X, y, True)\n        self._transform = <bound method DataFrameMapper._transform of Data...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), do_fit=True)\n    293             input_df = options.get('input_df', self.input_df)\n    294 \n    295             # columns could be a string or list of\n    296             # strings; we don't care because pandas\n    297             # will handle either.\n--> 298             Xt = self._get_col_subset(X, columns, input_df)\n        Xt = undefined\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        columns = 'new_tweet_post'\n        input_df = False\n    299             if transformers is not None:\n    300                 with add_column_names_to_exception(columns):\n    301                     if do_fit and hasattr(transformers, 'fit_transform'):\n    302                         Xt = _call_fit(transformers.fit_transform, Xt, y)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _get_col_subset(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), cols=['new_tweet_post'], input_df=False)\n    187 \n    188         elif isinstance(X, DataWrapper):\n    189             X = X.df  # fetch underlying data\n    190 \n    191         if return_vector:\n--> 192             t = X[cols[0]]\n        t = undefined\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        cols = ['new_tweet_post']\n    193         else:\n    194             t = X[cols]\n    195 \n    196         # return either a DataFrame/Series or a numpy array\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py in __getitem__(self=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), index='new_tweet_post')\n    326             return arr[()]\n    327         # Return ndarray otherwise\n    328         return arr.view(np.ndarray)\n    329 \n    330     def __getitem__(self, index):\n--> 331         res = super(memmap, self).__getitem__(index)\n        res = undefined\n        self.__getitem__ = <bound method memmap.__getitem__ of memmap([[0. ..., 0.        , 0.        ,\n         0.        ]])>\n        index = 'new_tweet_post'\n    332         if type(res) is memmap and res._mmap is None:\n    333             return res.view(type=ndarray)\n    334         return res\n\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n___________________________________________________________________________",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mJoblibIndexError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-52-d9eff0b324cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best score: %0.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best parameters set:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mJoblibIndexError\u001b[0m: JoblibIndexError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x01F55440, file \"C:\\Us...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x01F55440, file \"C:\\Us...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\S...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    492         if self.poller is not None:\n    493             self.poller.start()\n    494         self.kernel.start()\n    495         self.io_loop = ioloop.IOLoop.current()\n    496         try:\n--> 497             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    498         except KeyboardInterrupt:\n    499             pass\n    500 \n    501 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(340, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(340, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (340, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=340, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 8, 36, 24, 323722, tzinfo=tzutc()), 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'session': '9a89fd109ead475682fddc7b9f263ebf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'9a89fd109ead475682fddc7b9f263ebf']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 8, 36, 24, 323722, tzinfo=tzutc()), 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'session': '9a89fd109ead475682fddc7b9f263ebf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'9a89fd109ead475682fddc7b9f263ebf'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 3, 28, 8, 36, 24, 323722, tzinfo=tzutc()), 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'session': '9a89fd109ead475682fddc7b9f263ebf', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '54d32f74d0e04b4c8f6a1f6ab4feeff8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='if __name__ == \"__main__\":\\n    grid_search = Gri...\\'Accuracy:\\', accuracy_score(y_test, predictions))', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.If object>], cell_name='<ipython-input-52-d9eff0b324cd>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 10b952b0, execution_c...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x10C906A8, file \"<ipython-input-52-d9eff0b324cd>\", line 1>\n        result = <ExecutionResult object at 10b952b0, execution_c...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x10C906A8, file \"<ipython-input-52-d9eff0b324cd>\", line 1>, result=<ExecutionResult object at 10b952b0, execution_c...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x10C906A8, file \"<ipython-input-52-d9eff0b324cd>\", line 1>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#removing the altmeric word in article name\\ndef ...e_name = ' '.join(a)\\n    return article_name\\n    \", 'from fuzzywuzzy import fuzz\\n#replacing the tile ...           print(text)\\n    return text\\n    \\n     ', 'from fuzzywuzzy import fuzz\\nimport warnings\\nwarn...           print(text)\\n    return text\\n    \\n     ', 'def fuzzy_place_3(str_a, str_b, orig_str):\\n    t...   \\n                    \\n    return text\\n        ', 'import re\\nfrom fuzzywuzzy import fuzz', \"#negation count function\\nimport nltk\\nimport nltk...en(re.findall('\\\\w+_NEG', tweet))\\n    return count\", '#number of negative words in a tweet\\ndef neg_wor...       \\n            except: pass\\n    return count', '#no of positive words in a tweet\\ndef pos_word_co...       \\n            except: pass\\n    return count', '#overall score of the tweet\\ndef overall_score(tw...   except: \\n                pass\\n    return score', '#number of adjectives, adverbs and verbs in a tw...cept: pass        \\n    return count              ', '# creating the function to calculate the emotico...   #print(neg_emo_count)\\n    return neg_emo_count', '#count occurences of a ! and ?\\ndef count_occuren...         counter += 1\\n\\n            return counter', '#punctuation count\\nimport string\\ndef punc_count(...t(string.punctuation))\\n    return punct\\n    \\n    ', '# count number of user name mentions\\ndef user_me...weet)\\n    count= len(user_names)\\n    return count', \"import pandas as pd\\nxls = pd.ExcelFile('/Users/S...el(xls, 'pos')\\nneu_df = pd.read_excel(xls, 'neu')\", 'print(len(neg_df))\\nprint(len(pos_df))\\nprint(len(neu_df))', 'neg_df.reset_index(drop=True, inplace= True)\\npos...rue)\\nneu_df.reset_index(drop=True, inplace= True)', 'neg_train_df = neg_df[:800]\\nneg_val_df = neg_df[...n_df = neu_df[:900]\\nneu_val_df = neu_df[900:1100]', 'train_df = neg_train_df.append(pos_train_df, ign...train_df.append(neu_train_df, ignore_index= True)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {20: 2600, 22: 449, 26: 3049, 29: Positive    1100\nNeutral     1100\nNegative     849\nName: Label, dtype: int64, 39: count    3049.000000\nmean        9.824205\nstd   ...2.000000\nName: user_mention_count, dtype: float64, 42: 2600}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"#removing the altmeric word in article name\\ndef ...e_name = ' '.join(a)\\n    return article_name\\n    \", 'from fuzzywuzzy import fuzz\\n#replacing the tile ...           print(text)\\n    return text\\n    \\n     ', 'from fuzzywuzzy import fuzz\\nimport warnings\\nwarn...           print(text)\\n    return text\\n    \\n     ', 'def fuzzy_place_3(str_a, str_b, orig_str):\\n    t...   \\n                    \\n    return text\\n        ', 'import re\\nfrom fuzzywuzzy import fuzz', \"#negation count function\\nimport nltk\\nimport nltk...en(re.findall('\\\\w+_NEG', tweet))\\n    return count\", '#number of negative words in a tweet\\ndef neg_wor...       \\n            except: pass\\n    return count', '#no of positive words in a tweet\\ndef pos_word_co...       \\n            except: pass\\n    return count', '#overall score of the tweet\\ndef overall_score(tw...   except: \\n                pass\\n    return score', '#number of adjectives, adverbs and verbs in a tw...cept: pass        \\n    return count              ', '# creating the function to calculate the emotico...   #print(neg_emo_count)\\n    return neg_emo_count', '#count occurences of a ! and ?\\ndef count_occuren...         counter += 1\\n\\n            return counter', '#punctuation count\\nimport string\\ndef punc_count(...t(string.punctuation))\\n    return punct\\n    \\n    ', '# count number of user name mentions\\ndef user_me...weet)\\n    count= len(user_names)\\n    return count', \"import pandas as pd\\nxls = pd.ExcelFile('/Users/S...el(xls, 'pos')\\nneu_df = pd.read_excel(xls, 'neu')\", 'print(len(neg_df))\\nprint(len(pos_df))\\nprint(len(neu_df))', 'neg_df.reset_index(drop=True, inplace= True)\\npos...rue)\\nneu_df.reset_index(drop=True, inplace= True)', 'neg_train_df = neg_df[:800]\\nneg_val_df = neg_df[...n_df = neu_df[:900]\\nneu_val_df = neu_df[900:1100]', 'train_df = neg_train_df.append(pos_train_df, ign...train_df.append(neu_train_df, ignore_index= True)', ...], 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, 'Out': {20: 2600, 22: 449, 26: 3049, 29: Positive    1100\nNeutral     1100\nNegative     849\nName: Label, dtype: int64, 39: count    3049.000000\nmean        9.824205\nstd   ...2.000000\nName: user_mention_count, dtype: float64, 42: 2600}, 'Path': <class 'pathlib.Path'>, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'TfidfVectorizer': <class 'sklearn.feature_extraction.text.TfidfVectorizer'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Sarath\\<ipython-input-52-d9eff0b324cd> in <module>()\n      1 if __name__ == \"__main__\":\n      2     grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy', cv=3)\n----> 3     grid_search.fit(x_train, y_train)\n      4     print('Best score: %0.3f' % grid_search.best_score_)\n      5     print('Best parameters set:')\n      6     best_parameters = grid_search.best_estimator_.get_params()\n      7     #for param_name in sorted(parameters.keys()):\n      8      #   print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n      9     predictions = grid_search.predict(x_test)\n     10     print('Accuracy:', accuracy_score(y_test, predictions))\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=3, error_score='raise',\n       e...ore='warn',\n       scoring='accuracy', verbose=1), X=array([[0.        , 0.        , 0.        , ...,....., 0.        , 0.        ,\n        0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1], dtype=int32), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = array([[0.        , 0.        , 0.        , ...,....., 0.        , 0.        ,\n        0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1], dtype=int32)\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nIndexError                                         Thu Mar 28 16:37:25 2019\nPID: 10388               Python 3.6.5: C:\\Users\\Sarath\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]), {'score': make_scorer(accuracy_score)}, array([ 267,  268,  269, ..., 2597, 2598, 2599]), array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), 1, {'clf__C': 0.1, 'clf__gamma': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), scorer={'score': make_scorer(accuracy_score)}, train=array([ 267,  268,  269, ..., 2597, 2598, 2599]), test=array([   0,    1,    2,    3,    4,    5,    6,... 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]), verbose=1, parameters={'clf__C': 0.1, 'clf__gamma': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X_train = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y_train = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N..., shrinking=True,\n  tol=0.001, verbose=False))])>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', DataF...e, shrinking=True,\n  tol=0.001, verbose=False))]), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'vect': {}}\n        name = 'vect'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x0D17C348>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1])), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), None, memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), array([0, 0, 0, ..., 1, 1, 1]))\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), weight=None, X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method DataFrameMapper.fit_transform of D...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]))\n    383 \n    384         X       the data to fit\n    385 \n    386         y       the target vector relative to X, optional\n    387         \"\"\"\n--> 388         return self._transform(X, y, True)\n        self._transform = <bound method DataFrameMapper._transform of Data...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        y = array([0, 0, 0, ..., 1, 1, 1])\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _transform(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), y=array([0, 0, 0, ..., 1, 1, 1]), do_fit=True)\n    293             input_df = options.get('input_df', self.input_df)\n    294 \n    295             # columns could be a string or list of\n    296             # strings; we don't care because pandas\n    297             # will handle either.\n--> 298             Xt = self._get_col_subset(X, columns, input_df)\n        Xt = undefined\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...one, {})],\n        input_df=False, sparse=False)>\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        columns = 'new_tweet_post'\n        input_df = False\n    299             if transformers is not None:\n    300                 with add_column_names_to_exception(columns):\n    301                     if do_fit and hasattr(transformers, 'fit_transform'):\n    302                         Xt = _call_fit(transformers.fit_transform, Xt, y)\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in _get_col_subset(self=DataFrameMapper(default=False, df_out=False,\n   ...None, {})],\n        input_df=False, sparse=False), X=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), cols=['new_tweet_post'], input_df=False)\n    187 \n    188         elif isinstance(X, DataWrapper):\n    189             X = X.df  # fetch underlying data\n    190 \n    191         if return_vector:\n--> 192             t = X[cols[0]]\n        t = undefined\n        X = memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]])\n        cols = ['new_tweet_post']\n    193         else:\n    194             t = X[cols]\n    195 \n    196         # return either a DataFrame/Series or a numpy array\n\n...........................................................................\nC:\\Users\\Sarath\\Anaconda3\\lib\\site-packages\\numpy\\core\\memmap.py in __getitem__(self=memmap([[0.        , 0.        , 0.        , ......., 0.        , 0.        ,\n         0.        ]]), index='new_tweet_post')\n    326             return arr[()]\n    327         # Return ndarray otherwise\n    328         return arr.view(np.ndarray)\n    329 \n    330     def __getitem__(self, index):\n--> 331         res = super(memmap, self).__getitem__(index)\n        res = undefined\n        self.__getitem__ = <bound method memmap.__getitem__ of memmap([[0. ..., 0.        , 0.        ,\n         0.        ]])>\n        index = 'new_tweet_post'\n    332         if type(res) is memmap and res._mmap is None:\n    333             return res.view(type=ndarray)\n    334         return res\n\nIndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices\n___________________________________________________________________________"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.figure(1)\nplt.subplot(131)\ndf[df['Label']=='Positive']['pos_count'].value_counts().plot.bar(title='POS')\nplt.subplot(132)\ndf[df['Label']=='Negative']['pos_count'].value_counts().plot.bar(title = 'NEG')\nplt.subplot(133)\ndf[df['Label']=='Neutral']['pos_count'].value_counts().plot.bar(title = 'NEU')\n",
      "execution_count": 136,
      "outputs": [
        {
          "data": {
            "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x1bbb9210>"
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x1bb5b130>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nplt.figure(1)\nplt.subplot(131)\ndf[df['Label']=='Positive']['pos_tagging_count'].value_counts().plot.bar(title='POS',figsize=(8,5))\nplt.subplot(132)\ndf[df['Label']=='Negative']['pos_tagging_count'].value_counts().plot.bar(title='NEG')\nplt.subplot(133)\ndf[df['Label']=='Neutral']['pos_tagging_count'].value_counts().plot.bar(title='NEU')\n",
      "execution_count": 156,
      "outputs": [
        {
          "data": {
            "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x4f6f1570>"
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x4f5d3430>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df.columns",
      "execution_count": 166,
      "outputs": [
        {
          "data": {
            "text/plain": "Index(['citation', 'altid', 'count', 'profile_link', 'profile_name',\n       'display_name', 'tweet_post', 'post_time', 'post_URL', 'article_name',\n       'Language', 'sentiment', 'subjectivity', 'polarity', 'Label',\n       'new_tweet_post', 'number_of_uppercase', 'number_of_urls',\n       'number_of_hashtags', 'number_of_negation', 'neg_count', 'pos_count',\n       'overall_score', 'pos_tagging_count', 'Exclamation_count',\n       'question_mark_count', 'punc_count', 'user_mention_count',\n       'pos_emo_count', 'neg_emo_count'],\n      dtype='object')"
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df[df['Label']=='Positive']['number_of_urls'].value_counts()",
      "execution_count": 193,
      "outputs": [
        {
          "data": {
            "text/plain": "1    878\n0    108\n2    105\n3      8\n5      1\nName: number_of_urls, dtype: int64"
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "url=pd.crosstab(df['neg_count'],df['Label'])\nurl.div(url.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4), legend = True)",
      "execution_count": 159,
      "outputs": [
        {
          "data": {
            "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x4f6b8b10>"
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x4f90bbb0>"
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "tweet = 'worst paper too sad never outstanding'",
      "execution_count": 107,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "las_pol_2(tweet)",
      "execution_count": 108,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "1\n1\n"
        },
        {
          "data": {
            "text/plain": "1"
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "l = (tweet.split())[-1]",
      "execution_count": 83,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#number of adjectives, adverbs and verbs in a tweet\ndef pos_count(tweet):\n    count = 0\n    l = ['adj','adverb','verb']\n    for i in tweet.split():\n        if i in lexicon:\n            #print(i)\n            try:\n                pos_tag = lexicon[i][1]\n                if pos_tag in l:\n                    #print(lexicon[i])\n                    if lexicon[i][0] == 1:\n                        count+=1\n\n            except: \n                pass\n    return count     ",
      "execution_count": 160,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df['pos_tagg_pos_count'] = df['new_tweet_post'].apply(pos_count)",
      "execution_count": 162,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "i = 'New'",
      "execution_count": 141,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "lexicon[i]",
      "execution_count": 142,
      "outputs": [
        {
          "data": {
            "text/plain": "[]"
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "tweet = clean_tweet(tweet)\ntweet = preprocess(tweet)",
      "execution_count": 137,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "count = 0\nl = ['adj','adverb','verb']\nfor i in tweet.split():\n    if i in lexicon:\n        print(i)\n        try:\n            pos_tag = lexicon[i][1]\n            if pos_tag in l:\n                print(lexicon[i])\n                if lexicon[i][0] == -1:\n                    count+=1\n                    \n        except: \n            pass\nreturn count        ",
      "execution_count": 156,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "aggression\n[-1, 'adj', -1, 'noun']\nresearch\naggression\n[-1, 'adj', -1, 'noun']\n2\n"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from nltk.corpus import stopwords\ndef remove_stopwords(tweet):\n    \"\"\"Remove stop words from list of tokenized words\"\"\"\n    new_words = []\n    words = tweet.split()\n    for word in words:\n        if word not in stopwords.words('english'):\n            new_words.append(word)\n    tweet = ' '.join(new_words)        \n    return tweet",
      "execution_count": 127,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": " tweet = remove_stopwords(tweet)",
      "execution_count": 124,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "df['new_tweet_post'] = df['tweet_post'].apply(remove_stopwords)\ndf['new_title'] = df['article_name'].apply(remove_stopwords)",
      "execution_count": 71,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "new_tweet_post = []\nfor article, tpost in zip(df.article_name, df.tweet_post):\n    new_post = fuzzy_place_4(article, \"title\", tpost)\n    new_tweet_post.append(new_post)",
      "execution_count": 87,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "tweet = 'RT @autismcrisis: Autism means? Not a clear picture? https://t.co/kLZWAjfkar note: no SRS-asym…'\narticle_name = 'Association Between Chronic Physical Conditions and the Effectiveness of Collaborative Care for Depression'",
      "execution_count": 205,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "fuzzy_place_3(article_name,'title',tweet)",
      "execution_count": 206,
      "outputs": [
        {
          "data": {
            "text/plain": "'RT @autismcrisis: Autism means? Not a clear picture? https://t.co/kLZWAjfkar note: no SRS-asym…'"
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}